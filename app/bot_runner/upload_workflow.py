#!/usr/bin/env python3
"""
éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & è‡ªå‹•æ–‡å­—èµ·ã“ã—ãƒ»è¦ç´„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
ä¼šè­°çµ‚äº†å¾Œã«è‡ªå‹•ã§å®Ÿè¡Œã•ã‚Œã€éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€
æ–‡å­—èµ·ã“ã—ã¨è¦ç´„ï¼ˆè­°äº‹éŒ²ä½œæˆï¼‰ã‚’è¡Œã„ã¾ã™ã€‚
"""
import os
import sys
import time
import glob
import logging
import httpx

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# è¨­å®š
BACKEND_URL = os.environ.get('BACKEND_URL', 'http://host.docker.internal:8000')
RECORDINGS_DIR = os.environ.get('RECORDINGS_DIR', '/app/recordings')
POLL_INTERVAL = 5  # æ–‡å­—èµ·ã“ã—å®Œäº†å¾…æ©Ÿãƒãƒ¼ãƒªãƒ³ã‚°é–“éš”ï¼ˆç§’ï¼‰
POLL_TIMEOUT = 1800  # æœ€å¤§å¾…æ©Ÿæ™‚é–“ï¼ˆç§’ï¼‰


def find_latest_recording() -> str | None:
    """
    æœ€æ–°ã®éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    """
    pattern = os.path.join(RECORDINGS_DIR, "*.wav")
    files = glob.glob(pattern)
    
    if not files:
        return None
    
    # æ›´æ–°æ—¥æ™‚ãŒæœ€æ–°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿”ã™
    return max(files, key=os.path.getmtime)


def upload_file(filepath: str) -> dict:
    """
    éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    """
    logger.info(f"ğŸ“¤ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­: {filepath}")
    
    filename = os.path.basename(filepath)
    
    with open(filepath, 'rb') as f:
        files = {'file': (filename, f, 'audio/wav')}
        response = httpx.post(
            f"{BACKEND_URL}/api/upload",
            files=files,
            timeout=300  # å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ç”¨ã«5åˆ†
        )
    
    response.raise_for_status()
    result = response.json()
    logger.info(f"âœ… ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: job_id={result.get('job_id')}")
    return result


def trigger_transcription(job_id: str) -> dict:
    """
    æ–‡å­—èµ·ã“ã—ã‚’ãƒˆãƒªã‚¬ãƒ¼
    """
    logger.info(f"ğŸ”Š æ–‡å­—èµ·ã“ã—é–‹å§‹: job_id={job_id}")
    
    response = httpx.post(
        f"{BACKEND_URL}/api/transcribe",
        json={"job_id": job_id},
        timeout=60
    )
    
    response.raise_for_status()
    result = response.json()
    logger.info(f"âœ… æ–‡å­—èµ·ã“ã—ã‚¸ãƒ§ãƒ–é–‹å§‹: {result}")
    return result


def wait_for_transcription(job_id: str) -> dict:
    """
    æ–‡å­—èµ·ã“ã—å®Œäº†ã‚’å¾…æ©Ÿ
    """
    logger.info(f"â³ æ–‡å­—èµ·ã“ã—å®Œäº†å¾…æ©Ÿä¸­: job_id={job_id}")
    
    start_time = time.time()
    
    while True:
        response = httpx.get(
            f"{BACKEND_URL}/api/transcribe/status",
            params={"job_id": job_id},
            timeout=60
        )
        response.raise_for_status()
        result = response.json()
        
        status = result.get("status")
        
        if status == "TRANSCRIBED":
            logger.info("âœ… æ–‡å­—èµ·ã“ã—å®Œäº†")
            return result
        elif status == "FAILED":
            error_msg = result.get("error_message", "Unknown error")
            logger.error(f"âŒ æ–‡å­—èµ·ã“ã—å¤±æ•—: {error_msg}")
            raise RuntimeError(f"Transcription failed: {error_msg}")
        
        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒã‚§ãƒƒã‚¯
        elapsed = time.time() - start_time
        if elapsed > POLL_TIMEOUT:
            raise TimeoutError(f"Transcription timeout after {POLL_TIMEOUT} seconds")
        
        logger.info(f"   çŠ¶æ…‹: {status} (çµŒé: {int(elapsed)}ç§’)")
        time.sleep(POLL_INTERVAL)


def trigger_summarization(job_id: str) -> dict:
    """
    è¦ç´„ï¼ˆè­°äº‹éŒ²ä½œæˆï¼‰ã‚’ãƒˆãƒªã‚¬ãƒ¼
    """
    logger.info(f"ğŸ“ è¦ç´„ï¼ˆè­°äº‹éŒ²ä½œæˆï¼‰é–‹å§‹: job_id={job_id}")
    
    response = httpx.post(
        f"{BACKEND_URL}/api/summarize",
        json={"job_id": job_id},
        timeout=120
    )
    
    response.raise_for_status()
    result = response.json()
    logger.info(f"âœ… è¦ç´„å®Œäº†: status={result.get('status')}")
    return result


def main():
    """
    ãƒ¡ã‚¤ãƒ³å‡¦ç†
    """
    logger.info("=========================================")
    logger.info("  ğŸ“¤ éŒ²éŸ³ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & è‡ªå‹•å‡¦ç†ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼")
    logger.info("=========================================")
    logger.info(f"  Backend URL: {BACKEND_URL}")
    logger.info(f"  Recordings Dir: {RECORDINGS_DIR}")
    logger.info("")
    
    # æœ€æ–°ã®éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    recording_file = find_latest_recording()
    
    if not recording_file:
        logger.warning("âš ï¸ éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return 1
    
    logger.info(f"ğŸ“ éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {recording_file}")
    
    try:
        # 1. ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        upload_result = upload_file(recording_file)
        job_id = upload_result.get("job_id")
        
        if not job_id:
            logger.error("âŒ job_id ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return 1
        
        # 2. æ–‡å­—èµ·ã“ã—
        trigger_transcription(job_id)
        wait_for_transcription(job_id)
        
        # 3. è¦ç´„ï¼ˆè­°äº‹éŒ²ä½œæˆï¼‰
        summary_result = trigger_summarization(job_id)
        
        logger.info("")
        logger.info("=========================================")
        logger.info("  âœ… ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Œäº†")
        logger.info("=========================================")
        logger.info(f"  Job ID: {job_id}")
        logger.info(f"  Status: {summary_result.get('status')}")
        logger.info("")
        
        return 0
        
    except httpx.HTTPStatusError as e:
        logger.error(f"âŒ API ã‚¨ãƒ©ãƒ¼: {e.response.status_code} - {e.response.text}")
        return 1
    except Exception as e:
        logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())
