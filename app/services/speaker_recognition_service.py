"""
è©±è€…åˆ¥éŸ³å£°èªè­˜ã‚µãƒ¼ãƒ“ã‚¹

å„å‚åŠ è€…ã®éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å€‹åˆ¥ã«å‡¦ç†ã—ã€Azure Speechã§æ–‡å­—èµ·ã“ã—ã‚’è¡Œã†
"""
import io
import logging
import wave
from typing import Dict, Optional
from dataclasses import dataclass, field
from datetime import datetime
import threading
import queue

import azure.cognitiveservices.speech as speechsdk

from app.config import settings
from app.services.live_transcription_service import live_transcription_service

logger = logging.getLogger(__name__)


@dataclass
class SpeakerRecognizer:
    """è©±è€…ã”ã¨ã®éŸ³å£°èªè­˜å™¨"""
    user_id: int
    user_name: str
    audio_buffer: queue.Queue = field(default_factory=lambda: queue.Queue())
    recognizer: Optional[speechsdk.SpeechRecognizer] = None
    push_stream: Optional[speechsdk.audio.PushAudioInputStream] = None
    is_running: bool = False
    last_activity: datetime = field(default_factory=datetime.utcnow)


class SpeakerAudioRecognitionService:
    """
    è©±è€…åˆ¥éŸ³å£°èªè­˜ã‚µãƒ¼ãƒ“ã‚¹
    
    å„å‚åŠ è€…ã”ã¨ã«Azure Speechèªè­˜å™¨ã‚’ä½œæˆã—ã€
    å€‹åˆ¥ã®éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’æ–‡å­—èµ·ã“ã—ã™ã‚‹
    """
    
    def __init__(self, session_id: str):
        self.session_id = session_id
        self._recognizers: Dict[int, SpeakerRecognizer] = {}
        self._lock = threading.Lock()
        
        # Azure Speechè¨­å®š
        self.speech_config = speechsdk.SpeechConfig(
            subscription=settings.AZURE_SPEECH_KEY,
            region=settings.AZURE_SPEECH_REGION
        )
        self.speech_config.speech_recognition_language = "ja-JP"
        
        logger.info(f"ğŸ™ï¸ SpeakerAudioRecognitionService created for session: {session_id}")
    
    def process_audio(self, user_id: int, user_name: str, audio_data: bytes) -> None:
        """
        è©±è€…ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
        
        Args:
            user_id: Zoomå‚åŠ è€…ID
            user_name: å‚åŠ è€…å
            audio_data: PCM 16LE, 16kHz éŸ³å£°ãƒ‡ãƒ¼ã‚¿
        """
        with self._lock:
            if user_id not in self._recognizers:
                self._create_recognizer(user_id, user_name)
            
            recognizer = self._recognizers[user_id]
            recognizer.last_activity = datetime.utcnow()
            
            # PushStreamã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡
            if recognizer.push_stream:
                recognizer.push_stream.write(audio_data)
    
    def _create_recognizer(self, user_id: int, user_name: str) -> None:
        """è©±è€…ç”¨ã®èªè­˜å™¨ã‚’ä½œæˆ"""
        logger.info(f"ğŸ¤ Creating recognizer for user: {user_id} ({user_name})")
        
        # PushAudioInputStream ã‚’ä½œæˆï¼ˆPCM 16LE, 16kHz, monoï¼‰
        audio_format = speechsdk.audio.AudioStreamFormat(
            samples_per_second=16000,
            bits_per_sample=16,
            channels=1
        )
        push_stream = speechsdk.audio.PushAudioInputStream(stream_format=audio_format)
        audio_config = speechsdk.audio.AudioConfig(stream=push_stream)
        
        # èªè­˜å™¨ã‚’ä½œæˆ
        speech_recognizer = speechsdk.SpeechRecognizer(
            speech_config=self.speech_config,
            audio_config=audio_config
        )
        
        # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’è¨­å®š
        def on_recognized(evt: speechsdk.SpeechRecognitionEventArgs):
            if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:
                text = evt.result.text
                if text.strip():
                    logger.info(f"ğŸ“ [{user_name}] {text}")
                    
                    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ 
                    live_transcription_service.add_segment(
                        session_id=self.session_id,
                        speaker=user_name,
                        text=text
                    )
        
        def on_canceled(evt: speechsdk.SpeechRecognitionCanceledEventArgs):
            if evt.reason == speechsdk.CancellationReason.Error:
                logger.error(f"âŒ Recognition error for {user_name}: {evt.error_details}")
        
        speech_recognizer.recognized.connect(on_recognized)
        speech_recognizer.canceled.connect(on_canceled)
        
        # ç¶™ç¶šçš„èªè­˜ã‚’é–‹å§‹
        speech_recognizer.start_continuous_recognition()
        
        # èªè­˜å™¨ã‚’ä¿å­˜
        self._recognizers[user_id] = SpeakerRecognizer(
            user_id=user_id,
            user_name=user_name,
            recognizer=speech_recognizer,
            push_stream=push_stream,
            is_running=True
        )
    
    def stop_recognizer(self, user_id: int) -> None:
        """è©±è€…ã®èªè­˜å™¨ã‚’åœæ­¢"""
        with self._lock:
            if user_id in self._recognizers:
                recognizer = self._recognizers[user_id]
                
                if recognizer.push_stream:
                    recognizer.push_stream.close()
                
                if recognizer.recognizer:
                    recognizer.recognizer.stop_continuous_recognition()
                
                recognizer.is_running = False
                del self._recognizers[user_id]
                
                logger.info(f"ğŸ›‘ Recognizer stopped for user: {user_id}")
    
    def stop_all(self) -> None:
        """å…¨ã¦ã®èªè­˜å™¨ã‚’åœæ­¢"""
        with self._lock:
            user_ids = list(self._recognizers.keys())
        
        for user_id in user_ids:
            self.stop_recognizer(user_id)
        
        logger.info(f"ğŸ›‘ All recognizers stopped for session: {self.session_id}")
    
    def get_active_speakers(self) -> list:
        """ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªè©±è€…ä¸€è¦§ã‚’å–å¾—"""
        with self._lock:
            return [
                {
                    "user_id": r.user_id,
                    "user_name": r.user_name,
                    "is_running": r.is_running,
                    "last_activity": r.last_activity.isoformat()
                }
                for r in self._recognizers.values()
            ]


# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã®ã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ç®¡ç†
_session_services: Dict[str, SpeakerAudioRecognitionService] = {}
_services_lock = threading.Lock()


def get_speaker_recognition_service(session_id: str) -> SpeakerAudioRecognitionService:
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®è©±è€…èªè­˜ã‚µãƒ¼ãƒ“ã‚¹ã‚’å–å¾—ã¾ãŸã¯ä½œæˆ"""
    global _session_services
    
    with _services_lock:
        if session_id not in _session_services:
            _session_services[session_id] = SpeakerAudioRecognitionService(session_id)
        return _session_services[session_id]


def stop_speaker_recognition_service(session_id: str) -> None:
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®è©±è€…èªè­˜ã‚µãƒ¼ãƒ“ã‚¹ã‚’åœæ­¢"""
    global _session_services
    
    with _services_lock:
        if session_id in _session_services:
            _session_services[session_id].stop_all()
            del _session_services[session_id]
